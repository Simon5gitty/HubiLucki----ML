{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2e23553",
   "metadata": {},
   "source": [
    "# ML End-to-End Projekt: Student Performance Prediction\n",
    "\n",
    "**Autoren:** [Ihre Namen einfügen]  \n",
    "**Datum:** Oktober 2025  \n",
    "**OST - Ostschweizer Fachhochschule**\n",
    "\n",
    "![OST Logo](https://www.ost.ch/de/mediathek/_jcr_content/root/stage/image.img.3.high.jpg/1662646826512.jpg)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef783072",
   "metadata": {},
   "source": [
    "## (b) Einleitung\n",
    "\n",
    "### Beschreibung der Aufgabe\n",
    "Dieses Projekt befasst sich mit der Vorhersage der Prüfungsleistung (Exam_Score) von Studenten basierend auf verschiedenen Einflussfaktoren. Der Datensatz enthält 20 verschiedene Features, die verschiedene Aspekte des studentischen Lebens abbilden, darunter Lerngewohnheiten (Hours_Studied), Anwesenheit (Attendance), sozioökonomische Faktoren (Family_Income, Parental_Education_Level), persönliche Faktoren (Sleep_Hours, Motivation_Level) sowie schulische Rahmenbedingungen (Teacher_Quality, School_Type).\n",
    "\n",
    "### Anwendungsbereich\n",
    "Das entwickelte Modell kann in verschiedenen Bereichen des Bildungssektors eingesetzt werden:\n",
    "- **Frühwarnsysteme** für gefährdete Studenten, die Unterstützung benötigen\n",
    "- **Personalisierte Lernempfehlungen** basierend auf identifizierten Schwachstellen\n",
    "- **Ressourcenallokation** durch Bildungseinrichtungen zur gezielten Förderung\n",
    "- **Beratung** von Studenten und Eltern zur Optimierung der Lernbedingungen\n",
    "\n",
    "### Bedeutung\n",
    "Die frühzeitige Identifikation von Studenten mit Leistungsrisiken ermöglicht präventive Maßnahmen und gezielte Interventionen. Durch die Analyse der wichtigsten Einflussfaktoren können Bildungseinrichtungen datenbasierte Entscheidungen treffen, um die Lernergebnisse zu verbessern und Chancengleichheit zu fördern. Dies trägt zur Reduktion von Studienabbrüchen bei und erhöht die Gesamtqualität der Bildung.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca34d42e",
   "metadata": {},
   "source": [
    "## (c) Zielsetzung und Vorgehensweise\n",
    "\n",
    "### Zielsetzung\n",
    "**Hauptziel:** Entwicklung eines Machine Learning Modells zur präzisen Vorhersage des Exam_Score von Studenten (kontinuierlicher Wert zwischen 0 und 100 Punkten).\n",
    "\n",
    "**Teilziele:**\n",
    "1. Identifikation der wichtigsten Einflussfaktoren auf die Prüfungsleistung\n",
    "2. Entwicklung einer robusten ML-Pipeline für Datenverarbeitung und Modelltraining\n",
    "3. Vergleich verschiedener Regressionsalgorithmen\n",
    "4. Optimierung des besten Modells durch Hyperparameter-Tuning\n",
    "\n",
    "### Ansatz\n",
    "1. **Explorative Datenanalyse (EDA):** Verstehen der Datenstruktur, Identifikation von Mustern, Ausreißern und Korrelationen\n",
    "2. **Data Preprocessing:** Behandlung fehlender Werte, Feature Engineering, Encoding kategorischer Variablen\n",
    "3. **Feature Selection:** Identifikation der relevantesten Features\n",
    "4. **Pipeline-Entwicklung:** Aufbau einer automatisierten ML-Pipeline für reproduzierbare Ergebnisse\n",
    "5. **Modellvergleich:** Evaluation verschiedener Algorithmen (No Free Lunch Theorem)\n",
    "6. **Hyperparameter-Tuning:** Optimierung des besten Modells mittels Grid Search oder Random Search\n",
    "7. **Kreuzvalidierung:** Robuste Bewertung der Modellleistung\n",
    "8. **Final Testing:** Evaluation auf Test-Set\n",
    "\n",
    "### Metrik\n",
    "**Primäre Metrik:** **RMSE (Root Mean Squared Error)**  \n",
    "- RMSE bestraft größere Fehler stärker und ist gut interpretierbar in den Original-Einheiten (Punkte)\n",
    "\n",
    "**Zielvorgabe:** RMSE < 5.0 Punkte (entspricht ca. 5% Fehler bei einer Skala von 0-100)\n",
    "\n",
    "### Sekundäre Metriken\n",
    "- **R² Score:** Anteil der erklärten Varianz (Ziel: R² > 0.70)\n",
    "- **MAE (Mean Absolute Error):** Durchschnittlicher absoluter Fehler\n",
    "- **MAPE (Mean Absolute Percentage Error):** Prozentuale Abweichung\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e4f3f1",
   "metadata": {},
   "source": [
    "## (d) Explorative Datenanalyse (EDA)\n",
    "\n",
    "### 3.1 Daten laden und erste Inspektion\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39067925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bibliotheken importieren\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Regression Modelle\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Metriken\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Weitere Libraries nach Bedarf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Plotting Einstellungen\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e7a673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten laden\n",
    "# TODO: Pfad zur CSV-Datei anpassen\n",
    "df = pd.read_csv('StudentPerformanceFactors.csv')\n",
    "\n",
    "# Erste Inspektion\n",
    "print(\"=== Datensatz Übersicht ===\")\n",
    "print(f\"Anzahl Zeilen: {df.shape[0]}\")\n",
    "print(f\"Anzahl Spalten: {df.shape[1]}\")\n",
    "print(\"\\n=== Erste 5 Zeilen ===\")\n",
    "display(df.head())\n",
    "print(\"\\n=== Datentypen ===\")\n",
    "print(df.dtypes)\n",
    "print(\"\\n=== Fehlende Werte ===\")\n",
    "print(df.isnull().sum())\n",
    "print(\"\\n=== Statistische Kennzahlen ===\")\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081fb1a5",
   "metadata": {},
   "source": [
    "### 3.2 Datenbereinigung und Verständnis\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e1d5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fehlende Werte behandeln\n",
    "# Strategie festlegen: Imputation oder Entfernung?\n",
    "\n",
    "# TODO: Duplikate prüfen\n",
    "\n",
    "# TODO: Kategorische Variablen identifizieren und deren Unique Values anzeigen\n",
    "\n",
    "# TODO: Numerische Variablen identifizieren"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a748788",
   "metadata": {},
   "source": [
    "### 3.3 Univariate Analyse\n",
    "\n",
    "Analyse einzelner Variablen zur Verteilungsanalyse\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7dadf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Verteilung der Zielvariable (Exam_Score) visualisieren\n",
    "# Histogramm, Box-Plot, etc.\n",
    "\n",
    "# TODO: Verteilung numerischer Features visualisieren\n",
    "\n",
    "# TODO: Verteilung kategorischer Features visualisieren (Bar Charts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bf340f",
   "metadata": {},
   "source": [
    "### 3.4 Bivariate Analyse\n",
    "\n",
    "Analyse der Beziehung zwischen Features und der Zielvariable\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b313a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Korrelationsmatrix für numerische Features erstellen\n",
    "\n",
    "# TODO: Scatter Plots für wichtigste numerische Features vs. Exam_Score\n",
    "\n",
    "# TODO: Box Plots für kategorische Features vs. Exam_Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5524a1e8",
   "metadata": {},
   "source": [
    "### 3.5 Multivariate Analyse und Ausreißererkennung\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc5de845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Pairplot für ausgewählte wichtige Features\n",
    "\n",
    "# TODO: Ausreißer identifizieren (z.B. mit IQR-Methode oder Z-Score)\n",
    "\n",
    "# TODO: Entscheidung über Umgang mit Ausreißern dokumentieren"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9877ac36",
   "metadata": {},
   "source": [
    "### 3.6 Wichtigste Erkenntnisse aus der EDA\n",
    "\n",
    "**Zusammenfassung der EDA-Ergebnisse:**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a6ad67",
   "metadata": {},
   "source": [
    "# TODO: Hier die wichtigsten Erkenntnisse aus der EDA auflisten:\n",
    "# - Anzahl Features und Beobachtungen\n",
    "# - Fehlende Werte\n",
    "# - Wichtigste Korrelationen mit Zielvariable\n",
    "# - Auffällige Muster oder Ausreißer\n",
    "# - Verteilung der Zielvariable\n",
    "# etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f80530a1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## (e) Pipeline\n",
    "\n",
    "### 4.1 Data Preprocessing und Feature Engineering\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb9135b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test Split vorbereiten\n",
    "# TODO: Daten in X (Features) und y (Target) aufteilen\n",
    "\n",
    "# TODO: Train-Test Split durchführen (z.B. 80/20 oder 70/30)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a49b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "# TODO: Ggf. neue Features erstellen basierend auf EDA-Erkenntnissen\n",
    "# Beispiele:\n",
    "# - Interaktionen zwischen Features\n",
    "# - Binning kontinuierlicher Variablen\n",
    "# - Feature Transformationen (log, polynomial, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca27b8ea",
   "metadata": {},
   "source": [
    "### 4.2 Pipeline Aufbau\n",
    "\n",
    "Erstellung einer ML-Pipeline für automatisierte und reproduzierbare Datenverarbeitung\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43caa755",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Numerische und kategorische Features identifizieren\n",
    "# numerical_features = [...]\n",
    "# categorical_features = [...]\n",
    "\n",
    "# TODO: Preprocessing Pipeline für numerische Features erstellen\n",
    "# numerical_transformer = Pipeline(steps=[\n",
    "#     ('imputer', SimpleImputer(strategy='median')),\n",
    "#     ('scaler', StandardScaler())\n",
    "# ])\n",
    "\n",
    "# TODO: Preprocessing Pipeline für kategorische Features erstellen\n",
    "# categorical_transformer = Pipeline(steps=[\n",
    "#     ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "#     ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "# ])\n",
    "\n",
    "# TODO: ColumnTransformer erstellen\n",
    "# preprocessor = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         ('num', numerical_transformer, numerical_features),\n",
    "#         ('cat', categorical_transformer, categorical_features)\n",
    "#     ])\n",
    "\n",
    "# TODO: Pipeline mit Preprocessor testen\n",
    "# preprocessor.fit(X_train)\n",
    "# X_train_transformed = preprocessor.transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e50627",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## (f) No Free Lunch\n",
    "\n",
    "### 5.1 Auswahl geeigneter Lernalgorithmen\n",
    "\n",
    "Gemäß dem **No Free Lunch Theorem** gibt es keinen universell besten Algorithmus. Verschiedene Algorithmen müssen für dieses spezifische Problem getestet werden.\n",
    "\n",
    "**Ausgewählte Algorithmen für dieses Regressionsproblem:**\n",
    "\n",
    "1. **Linear Regression** - Baseline-Modell, schnell und interpretierbar\n",
    "2. **Ridge Regression** - Regularisierte lineare Regression (L2)\n",
    "3. **Lasso Regression** - Regularisierte lineare Regression (L1, Feature Selection)\n",
    "4. **ElasticNet** - Kombination aus Ridge und Lasso\n",
    "5. **Decision Tree Regressor** - Nicht-lineares Modell, interpretierbar\n",
    "6. **Random Forest Regressor** - Ensemble-Methode, robust\n",
    "7. **Gradient Boosting Regressor** - Leistungsstarkes Ensemble-Modell\n",
    "8. **Support Vector Regressor (SVR)** - Kernel-basiertes Modell\n",
    "9. **K-Nearest Neighbors (KNN)** - Instanz-basiertes Lernen\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4104f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Dictionary mit allen zu testenden Modellen erstellen\n",
    "# models = {\n",
    "#     'Linear Regression': LinearRegression(),\n",
    "#     'Ridge': Ridge(),\n",
    "#     'Lasso': Lasso(),\n",
    "#     'ElasticNet': ElasticNet(),\n",
    "#     'Decision Tree': DecisionTreeRegressor(random_state=42),\n",
    "#     'Random Forest': RandomForestRegressor(random_state=42),\n",
    "#     'Gradient Boosting': GradientBoostingRegressor(random_state=42),\n",
    "#     'SVR': SVR(),\n",
    "#     'KNN': KNeighborsRegressor()\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d33e39",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## (g) Validierung\n",
    "\n",
    "### 6.1 Kreuzvalidierung der Modelle\n",
    "\n",
    "Verwendung von K-Fold Cross-Validation für robuste Performance-Bewertung\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00947d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Funktion zur Evaluation aller Modelle mit Cross-Validation erstellen\n",
    "\n",
    "# TODO: Für jedes Modell:\n",
    "# - Pipeline erstellen (Preprocessor + Modell)\n",
    "# - Cross-Validation durchführen (z.B. 5-Fold oder 10-Fold)\n",
    "# - RMSE, MAE, R² berechnen\n",
    "# - Ergebnisse speichern\n",
    "\n",
    "# TODO: Ergebnisse in DataFrame sammeln und sortieren\n",
    "\n",
    "# TODO: Visualisierung der Modell-Performance (Barplot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b43c9eb",
   "metadata": {},
   "source": [
    "### 6.2 Hyperparameter-Tuning\n",
    "\n",
    "Optimierung des besten Modells durch systematische Hyperparameter-Suche\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d454fea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Bestes Modell aus Cross-Validation auswählen\n",
    "\n",
    "# TODO: Hyperparameter-Grid definieren für das beste Modell\n",
    "# param_grid = {\n",
    "#     'regressor__parameter1': [...],\n",
    "#     'regressor__parameter2': [...],\n",
    "# }\n",
    "\n",
    "# TODO: GridSearchCV oder RandomizedSearchCV durchführen\n",
    "# grid_search = GridSearchCV(\n",
    "#     pipeline,\n",
    "#     param_grid,\n",
    "#     cv=5,\n",
    "#     scoring='neg_root_mean_squared_error',\n",
    "#     n_jobs=-1,\n",
    "#     verbose=1\n",
    "# )\n",
    "\n",
    "# TODO: Beste Parameter anzeigen\n",
    "\n",
    "# TODO: Performance mit optimierten Hyperparametern bewerten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7394be78",
   "metadata": {},
   "source": [
    "### 6.3 Final Testing auf Test-Set\n",
    "\n",
    "Evaluation des finalen Modells auf bisher ungesehenen Daten\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2007e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Finales Modell auf Test-Set evaluieren\n",
    "# y_pred = final_model.predict(X_test)\n",
    "\n",
    "# TODO: Metriken berechnen\n",
    "# rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "# mae = mean_absolute_error(y_test, y_pred)\n",
    "# r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# TODO: Visualisierung der Vorhersagen\n",
    "# - Predicted vs Actual Scatter Plot\n",
    "# - Residuen Plot\n",
    "# - Feature Importance (falls verfügbar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b01ed8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## (h) Entscheid\n",
    "\n",
    "### 7.1 Modellauswahl und Begründung\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8391ee9",
   "metadata": {},
   "source": [
    "**Ausgewähltes Modell:** [Modellname einfügen]\n",
    "\n",
    "**Begründung der Wahl:**\n",
    "\n",
    "TODO: Begründung basierend auf folgenden Kriterien:\n",
    "\n",
    "1. **Performance-Metriken:**\n",
    "   - RMSE: [Wert]\n",
    "   - R² Score: [Wert]\n",
    "   - MAE: [Wert]\n",
    "   - Vergleich mit anderen Modellen\n",
    "\n",
    "2. **Interpretierbarkeit:**\n",
    "   - Wie gut können die Vorhersagen erklärt werden?\n",
    "   - Feature Importance verfügbar?\n",
    "\n",
    "3. **Komplexität vs. Performance Trade-off:**\n",
    "   - Ist die zusätzliche Komplexität durch bessere Performance gerechtfertigt?\n",
    "\n",
    "4. **Robustheit:**\n",
    "   - Wie stabil sind die Ergebnisse über verschiedene Cross-Validation Folds?\n",
    "\n",
    "5. **Praktikabilität:**\n",
    "   - Training- und Inferenzzeit\n",
    "   - Ressourcenanforderungen\n",
    "\n",
    "6. **Erfüllung der Zielvorgabe:**\n",
    "   - Wurde RMSE < 5.0 erreicht?\n",
    "\n",
    "**Zusammenfassung:** [Kurze Zusammenfassung der Entscheidung]\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bc08f2",
   "metadata": {},
   "source": [
    "### 7.2 Feature Importance und Modellinterpretation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2911d688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Feature Importance extrahieren (falls verfügbar)\n",
    "# Für Tree-based Modelle: feature_importances_\n",
    "# Für lineare Modelle: Koeffizienten\n",
    "\n",
    "# TODO: Top 10 wichtigste Features visualisieren\n",
    "\n",
    "# TODO: Interpretation der wichtigsten Features\n",
    "# Welche Faktoren haben den größten Einfluss auf die Exam_Score?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90194598",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## (i) Schlussfolgerung und Ausblick\n",
    "\n",
    "### 8.1 Zusammenfassung der Ergebnisse\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0237b6da",
   "metadata": {},
   "source": [
    "**Erreichte Ziele:**\n",
    "\n",
    "TODO: Zusammenfassung der wichtigsten Erkenntnisse:\n",
    "\n",
    "1. **Datenverständnis:**\n",
    "   - [Anzahl Samples und Features]\n",
    "   - [Wichtigste Einflussfaktoren identifiziert]\n",
    "\n",
    "2. **Modellperformance:**\n",
    "   - [Bestes Modell und erreichte Metriken]\n",
    "   - [Vergleich mit Zielvorgabe]\n",
    "\n",
    "3. **Praktische Implikationen:**\n",
    "   - [Was bedeuten die Ergebnisse für den Bildungssektor?]\n",
    "   - [Welche Handlungsempfehlungen lassen sich ableiten?]\n",
    "\n",
    "4. **Herausforderungen:**\n",
    "   - [Welche Schwierigkeiten gab es?]\n",
    "   - [Limitationen des Modells]\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db074ae",
   "metadata": {},
   "source": [
    "### 8.2 Weiterführende Untersuchungen\n",
    "\n",
    "**Mögliche Verbesserungen und zukünftige Arbeiten:**\n",
    "\n",
    "1. **Erweiterte Feature Engineering:**\n",
    "   - Polynomial Features\n",
    "   - Interaktionsterme zwischen wichtigen Features\n",
    "   - Zeitbasierte Features (falls relevant)\n",
    "\n",
    "2. **Weitere Algorithmen:**\n",
    "   - XGBoost, LightGBM, CatBoost\n",
    "   - Neural Networks (MLPRegressor)\n",
    "   - Stacking Ensemble\n",
    "\n",
    "3. **Datenqualität:**\n",
    "   - Sammlung zusätzlicher Daten\n",
    "   - Verbesserung der Datenqualität\n",
    "   - Behandlung von Imbalance (falls vorhanden)\n",
    "\n",
    "4. **Modellinterpretation:**\n",
    "   - SHAP Values für detaillierte Erklärungen\n",
    "   - LIME für lokale Interpretierbarkeit\n",
    "   - Partial Dependence Plots\n",
    "\n",
    "5. **Deployment:**\n",
    "   - Entwicklung einer Web-App für Vorhersagen\n",
    "   - API-Entwicklung\n",
    "   - Monitoring der Modellperformance in Produktion\n",
    "\n",
    "6. **Domänenspezifische Ansätze:**\n",
    "   - Segmentierung nach Studentengruppen\n",
    "   - Unterschiedliche Modelle für verschiedene Schulstufen\n",
    "   - Integration von Zeitreihenanalyse (Entwicklung über mehrere Semester)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601514f0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## (j) Referenzen\n",
    "\n",
    "### Datenquelle\n",
    "\n",
    "TODO: Quelle des Datensatzes angeben\n",
    "- **Datensatz:** StudentPerformanceFactors.csv\n",
    "- **Herkunft:** [URL oder Quelle einfügen]\n",
    "- **Beschreibung:** [Kurze Beschreibung der Datenherkunft]\n",
    "\n",
    "### Literatur und Quellen\n",
    "\n",
    "TODO: Verwendete Quellen auflisten\n",
    "\n",
    "**Bücher:**\n",
    "1. Géron, A. (2019). *Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow* (2nd ed.). O'Reilly Media.\n",
    "2. James, G., Witten, D., Hastie, T., & Tibshirani, R. (2013). *An Introduction to Statistical Learning*. Springer.\n",
    "\n",
    "**Papers:**\n",
    "1. [Relevante wissenschaftliche Publikationen zum Thema Student Performance Prediction]\n",
    "\n",
    "**Online-Ressourcen:**\n",
    "1. Scikit-learn Documentation: https://scikit-learn.org/\n",
    "2. Pandas Documentation: https://pandas.pydata.org/\n",
    "3. Seaborn Documentation: https://seaborn.pydata.org/\n",
    "4. [Weitere verwendete Online-Ressourcen]\n",
    "\n",
    "**Code-Quellen:**\n",
    "- [Falls Code von anderen Quellen verwendet wurde, hier dokumentieren]\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68494cd",
   "metadata": {},
   "source": [
    "## Eigenständigkeitserklärung\n",
    "\n",
    "Hiermit bestätige ich / bestätigen wir, dass ich / wir die vorliegende Arbeit selbständig verfasst und keine anderen als die angegebenen Hilfsmittel benutzt habe/haben. Die Stellen der Arbeit, die dem Wortlaut oder dem Sinn nach anderen Werken (dazu zählen auch Internetquellen) entnommen sind, wurden unter Angabe der Quelle kenntlich gemacht.\n",
    "\n",
    "**Datum:** [Datum einfügen]\n",
    "\n",
    "**Unterschrift(en):** [Name(n) einfügen]\n",
    "\n",
    "---\n",
    "\n",
    "**Ende des Dokuments**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
